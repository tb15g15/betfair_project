{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betfair data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LoginResource>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import betfairlightweight\n",
    "from betfairlightweight import filters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path, PurePath #To define open and save locations that are cross-compatible between Windows/Linux\n",
    "from bz2 import BZ2File #To unzip the Betfair data from its downloaded format\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project_dir = Path.cwd().parents[1]\n",
    "logins_dir = project_dir / 'api_logins.json'\n",
    "\n",
    "with open(logins_dir) as f:\n",
    "    login_dict =  json.load(f)\n",
    "    \n",
    "trading = betfairlightweight.APIClient(username=login_dict['my_username'],\n",
    "                                       password=login_dict['my_password'],\n",
    "                                       app_key=login_dict['my_app_key'],\n",
    "                                       certs=login_dict['certs_path'])\n",
    "\n",
    "trading.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-01-01T00:00:00', 'purchaseItemId': 42364}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-02-01T00:00:00', 'purchaseItemId': 42364}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-03-01T00:00:00', 'purchaseItemId': 42364}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-04-01T00:00:00', 'purchaseItemId': 41549}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-05-01T00:00:00', 'purchaseItemId': 41549}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2016-01-01T00:00:00', 'purchaseItemId': 25202}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2017-06-01T00:00:00', 'purchaseItemId': 770}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-01-01T00:00:00', 'purchaseItemId': 24527}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-02-01T00:00:00', 'purchaseItemId': 24527}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2019-03-01T00:00:00', 'purchaseItemId': 28609}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2019-12-01T00:00:00', 'purchaseItemId': 25201}\n",
      "{'sport': 'Horse Racing', 'plan': 'Pro Plan', 'forDate': '2020-04-01T00:00:00', 'purchaseItemId': 42365}\n",
      "{'sport': 'Horse Racing', 'plan': 'Pro Plan', 'forDate': '2020-05-01T00:00:00', 'purchaseItemId': 42365}\n"
     ]
    }
   ],
   "source": [
    "# Lists the data that you have purchased on your Betfair account\n",
    "my_data = trading.historic.get_my_data()\n",
    "for i in my_data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'marketTypesCollection': [{'name': '', 'count': 19}, {'name': 'MATCH_BET', 'count': 54}, {'name': 'OTHER_PLACE', 'count': 18}, {'name': 'PLACE', 'count': 96}, {'name': 'RACE_WIN_DIST', 'count': 3}, {'name': 'WIN', 'count': 142}], 'countriesCollection': [{'name': 'AU', 'count': 231}, {'name': 'HK', 'count': 2}, {'name': 'JP', 'count': 25}, {'name': 'SE', 'count': 32}, {'name': 'US', 'count': 42}], 'fileTypeCollection': [{'name': 'E', 'count': 19}, {'name': 'M', 'count': 313}]}\n"
     ]
    }
   ],
   "source": [
    "# Breaks down the contents of the data you want to look into\n",
    "collection_options = trading.historic.get_collection_options(\n",
    "    \"Horse Racing\", \"Pro Plan\", 1, 4, 2020, 1, 4, 2020\n",
    ")\n",
    "\n",
    "print(collection_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'totalSizeMB': 120, 'fileCount': 332}\n"
     ]
    }
   ],
   "source": [
    "basket_size = trading.historic.get_data_size(\n",
    "    \"Horse Racing\", \"Pro Plan\", 1, 4, 2020, 1, 4, 2020\n",
    ")\n",
    "print(basket_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262288.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262291.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262294.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262297.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262314.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262300.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262317.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262303.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262320.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262306.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262323.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262309.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262326.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262329.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262332.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262335.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262338.bz2', '/xds_nfs/edp_processed/PRO/2020/Apr/1/29762726/1.170262341.bz2']\n"
     ]
    }
   ],
   "source": [
    "# Test sample, April 1st US horse racing data\n",
    "file_list = trading.historic.get_file_list(\n",
    "    \"Horse Racing\",\n",
    "    \"Pro Plan\",\n",
    "    from_day=1,\n",
    "    from_month=4,\n",
    "    from_year=2020,\n",
    "    to_day=1,\n",
    "    to_month=4,\n",
    "    to_year=2020,\n",
    "    market_types_collection=[\"WIN\", \"PLACE\"],\n",
    "    countries_collection=[\"US\"],\n",
    "    file_type_collection=[\"M\"],\n",
    ")\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/xds_nfs/edp_processed/PRO/2020/Apr/1/29762723/1.170262291.bz2\n",
      "1.170262291.bz2\n"
     ]
    }
   ],
   "source": [
    "# Downloading the first file in that list. Each file is one race.\n",
    "file = file_list[1]\n",
    "print(file)\n",
    "download = trading.historic.download_file(file_path=file)\n",
    "print(download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the bz2 file to the working directory\n",
    "filename = str(download)\n",
    "zipfile = BZ2File(filename) # open the file\n",
    "data = zipfile.read() # get the decompressed data\n",
    "newfilepath = filename[:-4] # assuming the filepath ends with .bz2\n",
    "open(newfilepath, 'wb').write(data) # write a uncompressed file\n",
    "zipfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using stream listener to read extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from betfairlightweight import StreamListener\n",
    "from betfairlightweight.streaming.stream import MarketStream\n",
    "\n",
    "class HistoricalStream(MarketStream):\n",
    "    # create custom listener and stream\n",
    "\n",
    "    def __init__(self, listener):\n",
    "        super(HistoricalStream, self).__init__(listener)\n",
    "        with open(\"output.txt\", \"w\") as output:\n",
    "            output.write(\"Time,MarketId,Status,Inplay,SelectionId,LastPriceTraded,TotalMatched\\n\")\n",
    "\n",
    "    def on_process(self, market_books):\n",
    "        with open(\"output.txt\", \"a\") as output:\n",
    "            for market_book in market_books:\n",
    "                for runner in market_book.runners:\n",
    "\n",
    "                    # how to get runner details from the market definition\n",
    "                    market_def = market_book.market_definition\n",
    "                    runners_dict = {\n",
    "                        (runner.selection_id, runner.handicap): runner\n",
    "                        for runner in market_def.runners\n",
    "                    }\n",
    "                    runner_def = runners_dict.get(\n",
    "                        (runner.selection_id, runner.handicap)\n",
    "                    )\n",
    "\n",
    "                    output.write(\n",
    "                        \"%s,%s,%s,%s,%s,%s,%s\\n\"\n",
    "                        % (\n",
    "                            market_book.publish_time,\n",
    "                            market_book.market_id,\n",
    "                            market_book.status,\n",
    "                            market_book.inplay,\n",
    "                            runner.selection_id,\n",
    "                            runner.last_price_traded or \"\",\n",
    "                            runner.total_matched or \"\",\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "\n",
    "class HistoricalListener(StreamListener):\n",
    "    def _add_stream(self, unique_id, stream_type):\n",
    "        if stream_type == \"marketSubscription\":\n",
    "            return HistoricalStream(self)\n",
    "        \n",
    "listener = HistoricalListener(max_latency=None)\n",
    "\n",
    "stream = trading.streaming.create_historical_stream(\n",
    "    directory=newfilepath,\n",
    "    listener=listener,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.start()\n",
    "#fills output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
